{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LIWC implementation\n",
    "- https://pypi.org/project/liwc-analysis/\n",
    "- https://github.com/dfederschmidt/pyliwc\n",
    "- https://radimrehurek.com/gensim/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import gensim\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "from collections import Counter\n",
    "from pyliwc.core import LIWC\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\TK\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -e git+https://github.com/dfederschmidt/pyliwc#egg=pyliwc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "liwc = LIWC(\"LIWC2015_English_Flat.dic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-example to have a try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11314, 1)\n"
     ]
    }
   ],
   "source": [
    "# fetch the dataset and put it in a dataframe\n",
    "news_data = fetch_20newsgroups(shuffle=True, random_state=42)\n",
    "df_news = pd.DataFrame(news_data[\"data\"], columns=[\"text\"])\n",
    "print(df_news.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From: lerxst@wam.umd.edu (where's my thing)\\nS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From: guykuo@carson.u.washington.edu (Guy Kuo)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From: twillis@ec.ecn.purdue.edu (Thomas E Will...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From: jgreen@amber (Joe Green)\\nSubject: Re: W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From: jcm@head-cfa.harvard.edu (Jonathan McDow...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  From: lerxst@wam.umd.edu (where's my thing)\\nS...\n",
       "1  From: guykuo@carson.u.washington.edu (Guy Kuo)...\n",
       "2  From: twillis@ec.ecn.purdue.edu (Thomas E Will...\n",
       "3  From: jgreen@amber (Joe Green)\\nSubject: Re: W...\n",
       "4  From: jcm@head-cfa.harvard.edu (Jonathan McDow..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# run without multiprocessing\n",
    "scores = liwc.process_df(df_news, \"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>achiev</th>\n",
       "      <th>adj</th>\n",
       "      <th>adverb</th>\n",
       "      <th>affect</th>\n",
       "      <th>affiliation</th>\n",
       "      <th>anger</th>\n",
       "      <th>anx</th>\n",
       "      <th>article</th>\n",
       "      <th>assent</th>\n",
       "      <th>auxverb</th>\n",
       "      <th>...</th>\n",
       "      <th>social</th>\n",
       "      <th>space</th>\n",
       "      <th>swear</th>\n",
       "      <th>tentat</th>\n",
       "      <th>they</th>\n",
       "      <th>time</th>\n",
       "      <th>verb</th>\n",
       "      <th>we</th>\n",
       "      <th>work</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>9.166667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>17.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.639344</td>\n",
       "      <td>4.098361</td>\n",
       "      <td>1.639344</td>\n",
       "      <td>4.918033</td>\n",
       "      <td>1.639344</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.918033</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.737705</td>\n",
       "      <td>...</td>\n",
       "      <td>12.295082</td>\n",
       "      <td>2.459016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.819672</td>\n",
       "      <td>1.639344</td>\n",
       "      <td>10.655738</td>\n",
       "      <td>8.196721</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.459016</td>\n",
       "      <td>1.639344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.615385</td>\n",
       "      <td>5.538462</td>\n",
       "      <td>6.769231</td>\n",
       "      <td>4.923077</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.461538</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>9.230769</td>\n",
       "      <td>...</td>\n",
       "      <td>6.153846</td>\n",
       "      <td>5.846154</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.076923</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.923077</td>\n",
       "      <td>16.615385</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.153846</td>\n",
       "      <td>0.307692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5.714286</td>\n",
       "      <td>4.761905</td>\n",
       "      <td>3.809524</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>4.761905</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.809524</td>\n",
       "      <td>...</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>3.809524</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>11.428571</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>0.952381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5.590062</td>\n",
       "      <td>4.347826</td>\n",
       "      <td>4.968944</td>\n",
       "      <td>1.242236</td>\n",
       "      <td>0.621118</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.453416</td>\n",
       "      <td>1.242236</td>\n",
       "      <td>9.316770</td>\n",
       "      <td>...</td>\n",
       "      <td>5.590062</td>\n",
       "      <td>3.105590</td>\n",
       "      <td>0.621118</td>\n",
       "      <td>4.968944</td>\n",
       "      <td>1.242236</td>\n",
       "      <td>4.347826</td>\n",
       "      <td>14.285714</td>\n",
       "      <td>0.621118</td>\n",
       "      <td>1.863354</td>\n",
       "      <td>0.621118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     achiev       adj    adverb    affect  affiliation     anger       anx  \\\n",
       "0       NaN  2.500000  2.500000  1.666667     0.833333       NaN       NaN   \n",
       "1  1.639344  4.098361  1.639344  4.918033     1.639344       NaN       NaN   \n",
       "2  0.615385  5.538462  6.769231  4.923077     0.307692  0.615385       NaN   \n",
       "3       NaN  5.714286  4.761905  3.809524          NaN       NaN  0.952381   \n",
       "4       NaN  5.590062  4.347826  4.968944     1.242236  0.621118       NaN   \n",
       "\n",
       "     article    assent    auxverb  ...     social     space     swear  \\\n",
       "0   7.500000       NaN  10.000000  ...   7.500000  9.166667       NaN   \n",
       "1   4.918033       NaN   5.737705  ...  12.295082  2.459016       NaN   \n",
       "2  10.461538  0.307692   9.230769  ...   6.153846  5.846154       NaN   \n",
       "3   4.761905       NaN   3.809524  ...   2.857143  3.809524       NaN   \n",
       "4   7.453416  1.242236   9.316770  ...   5.590062  3.105590  0.621118   \n",
       "\n",
       "     tentat      they       time       verb        we      work       you  \n",
       "0  5.000000       NaN   4.166667  17.500000       NaN  3.333333  2.500000  \n",
       "1  0.819672  1.639344  10.655738   8.196721       NaN  2.459016  1.639344  \n",
       "2  7.076923       NaN   4.923077  16.615385       NaN  2.153846  0.307692  \n",
       "3  2.857143       NaN   0.952381  11.428571       NaN  6.666667  0.952381  \n",
       "4  4.968944  1.242236   4.347826  14.285714  0.621118  1.863354  0.621118  \n",
       "\n",
       "[5 rows x 73 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now set up our own LIWC categories set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "liwcPath = 'LIWC2015_English_Flat.dic'\n",
    "LIWC_file = open(liwcPath, 'r') # LIWC dictionary\n",
    "\n",
    "# set up the category index-word dictionary\n",
    "catNames = {}\n",
    "LIWC_file.readline() #skips first '%' line\n",
    "line = LIWC_file.readline()\n",
    "lookup = []\n",
    "while '%' not in line:\n",
    "    keyval = line.split('\\t')\n",
    "    key = keyval[1].strip()\n",
    "    value = keyval[0]\n",
    "    catNames[key] = value\n",
    "    line = LIWC_file.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[re.compile('accept'), re.compile('accepta*'), re.compile('accepted'), re.compile('accepting'), re.compile('accepts'), re.compile('active'), re.compile('actively'), re.compile('admir*'), re.compile('ador*'), re.compile('advantag*'), re.compile('adventur*'), re.compile('affection*'), re.compile('agree'), re.compile('agreeable'), re.compile('agreeableness'), re.compile('agreeably'), re.compile('agreed'), re.compile('agreeing'), re.compile('agreement*'), re.compile('agrees'), re.compile('alright*'), re.compile('amaze*'), re.compile('amazing'), re.compile('amazingly'), re.compile('amor*'), re.compile('amus*'), re.compile('aok'), re.compile('appreciat*'), re.compile('approv*'), re.compile('assur*')]\n"
     ]
    }
   ],
   "source": [
    "def word_collection(category_):\n",
    "    flexicon = open('LIWC2015_English_Flat.dic', encoding='utf-8')\n",
    "    # read all LIWC words from file\n",
    "    wordlines = [line.strip() for line in flexicon]\n",
    "    # each line has a word or a stem followed by * and numbers of the word classes it is in\n",
    "    # word class 126 is positive emotion and 127 is negative emotion\n",
    "    result = []\n",
    "    category_index = catNames[category_]\n",
    "    for line in wordlines:\n",
    "        if not line == '':\n",
    "            items = line.split()\n",
    "            word = items[0]\n",
    "            classes = items[1:]\n",
    "            for c in classes:\n",
    "                if c == category_index:\n",
    "                    if '(' not in word and ')' not in word:\n",
    "                        result.append(re.compile(word))\n",
    "    return result\n",
    "# test sample\n",
    "print(word_collection('posemo')[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# check wether a given word would be consistent with the cluster\n",
    "p = re.compile('abstain*')\n",
    "print(p.match('abstainy') == None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categories to consider\n",
    "- Positive emotion, Negative emotion, Female references, Male references\n",
    "- Insight, Tentative, Certainty, Differentiation, Risk, Future focus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[re.compile('actually'), re.compile('adjust*'), re.compile('against'), re.compile(\"ain't\"), re.compile('aint'), re.compile('alternativ*'), re.compile('although'), re.compile('apart'), re.compile(\"aren't\"), re.compile('arent'), re.compile('but'), re.compile(\"can't\"), re.compile('cannot'), re.compile('cant'), re.compile('despite'), re.compile(\"didn't\"), re.compile('didnt'), re.compile('differ'), re.compile('differed'), re.compile('difference*')]\n"
     ]
    }
   ],
   "source": [
    "# give topics list\n",
    "topics = ['posemo', 'negemo', 'female', 'male', 'insight', \n",
    "          'tentat', 'certain', 'differ', 'risk', 'focusfuture']\n",
    "# set up a sub-dictionary for these topics\n",
    "sub_dic = {}\n",
    "for topic in topics:\n",
    "    sub_dic[topic] = word_collection(topic)\n",
    "# test case\n",
    "print(sub_dic['differ'][:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Go back to our previous comments collection and check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>bomrank</th>\n",
       "      <th>remove</th>\n",
       "      <th>bomtitle</th>\n",
       "      <th>imdblink</th>\n",
       "      <th>bomlink</th>\n",
       "      <th>studio</th>\n",
       "      <th>totalusgross$</th>\n",
       "      <th>totaltheater</th>\n",
       "      <th>openingusgross$</th>\n",
       "      <th>openingtheaters</th>\n",
       "      <th>opendate</th>\n",
       "      <th>closedate</th>\n",
       "      <th>critic ratings_avg</th>\n",
       "      <th>critic rating_var</th>\n",
       "      <th>user_avg</th>\n",
       "      <th>user_var</th>\n",
       "      <th>critic_ratings_comments</th>\n",
       "      <th>critic_ratings_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2004.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Shrek 2</td>\n",
       "      <td>http://www.imdb.com/title/tt0298148/</td>\n",
       "      <td>http://www.boxofficemojo.com/movies/?id=shrek2...</td>\n",
       "      <td>DW</td>\n",
       "      <td>441226247.0</td>\n",
       "      <td>4223.0</td>\n",
       "      <td>108037878.0</td>\n",
       "      <td>4163.0</td>\n",
       "      <td>5/19</td>\n",
       "      <td>11/25</td>\n",
       "      <td>75.0</td>\n",
       "      <td>94.4</td>\n",
       "      <td>7.2</td>\n",
       "      <td>2.37960</td>\n",
       "      <td>Lightning strikes twice, but not as brilliant...</td>\n",
       "      <td>90.0||88.0||80.0||80.0||80.0||75.0||75.0||70.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2004.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Spider-Man 2</td>\n",
       "      <td>http://www.imdb.com/title/tt0316654/</td>\n",
       "      <td>http://www.boxofficemojo.com/movies/?id=spider...</td>\n",
       "      <td>Sony</td>\n",
       "      <td>373585825.0</td>\n",
       "      <td>4166.0</td>\n",
       "      <td>88156227.0</td>\n",
       "      <td>4152.0</td>\n",
       "      <td>6/30</td>\n",
       "      <td>12/19</td>\n",
       "      <td>83.0</td>\n",
       "      <td>115.2</td>\n",
       "      <td>7.3</td>\n",
       "      <td>2.86249</td>\n",
       "      <td>The pleasure is doubled in Spider-Man 2. Crac...</td>\n",
       "      <td>100.0||100.0||100.0||91.0||90.0||90.0||88.0||8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2004.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Passion of the Christ</td>\n",
       "      <td>http://www.imdb.com/title/tt0335345/</td>\n",
       "      <td>http://www.boxofficemojo.com/movies/?id=passio...</td>\n",
       "      <td>NM</td>\n",
       "      <td>370274604.0</td>\n",
       "      <td>3408.0</td>\n",
       "      <td>83848082.0</td>\n",
       "      <td>3043.0</td>\n",
       "      <td>2/25</td>\n",
       "      <td>7/29</td>\n",
       "      <td>47.0</td>\n",
       "      <td>663.9</td>\n",
       "      <td>7.2</td>\n",
       "      <td>6.34920</td>\n",
       "      <td>This is not a sermon or a homily, but a visua...</td>\n",
       "      <td>100.0||80.0||80.0||75.0||63.0||63.0||50.0||50....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Meet the Fockers</td>\n",
       "      <td>http://www.imdb.com/title/tt0290002/</td>\n",
       "      <td>http://www.boxofficemojo.com/movies/?id=meetth...</td>\n",
       "      <td>Uni.</td>\n",
       "      <td>279261160.0</td>\n",
       "      <td>3554.0</td>\n",
       "      <td>46120980.0</td>\n",
       "      <td>3518.0</td>\n",
       "      <td>12/22</td>\n",
       "      <td>6/16</td>\n",
       "      <td>41.0</td>\n",
       "      <td>298.8</td>\n",
       "      <td>6.3</td>\n",
       "      <td>2.78720</td>\n",
       "      <td>One of those relatively rare comedies that's ...</td>\n",
       "      <td>70.0||63.0||60.0||60.0||50.0||50.0||50.0||40.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2004.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Incredibles</td>\n",
       "      <td>http://www.imdb.com/title/tt0317705/</td>\n",
       "      <td>http://www.boxofficemojo.com/movies/?id=incred...</td>\n",
       "      <td>BV</td>\n",
       "      <td>261441092.0</td>\n",
       "      <td>3933.0</td>\n",
       "      <td>70467623.0</td>\n",
       "      <td>3933.0</td>\n",
       "      <td>11/5</td>\n",
       "      <td>4/14</td>\n",
       "      <td>90.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.39500</td>\n",
       "      <td>Pixar again hitches top-notch storytelling to...</td>\n",
       "      <td>100.0||100.0||100.0||100.0||100.0||90.0||90.0|...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     year  bomrank  remove                   bomtitle  \\\n",
       "0  2004.0      1.0     NaN                    Shrek 2   \n",
       "1  2004.0      2.0     NaN               Spider-Man 2   \n",
       "2  2004.0      3.0     NaN  The Passion of the Christ   \n",
       "3  2004.0      4.0     NaN           Meet the Fockers   \n",
       "4  2004.0      5.0     NaN            The Incredibles   \n",
       "\n",
       "                               imdblink  \\\n",
       "0  http://www.imdb.com/title/tt0298148/   \n",
       "1  http://www.imdb.com/title/tt0316654/   \n",
       "2  http://www.imdb.com/title/tt0335345/   \n",
       "3  http://www.imdb.com/title/tt0290002/   \n",
       "4  http://www.imdb.com/title/tt0317705/   \n",
       "\n",
       "                                             bomlink studio  totalusgross$  \\\n",
       "0  http://www.boxofficemojo.com/movies/?id=shrek2...     DW    441226247.0   \n",
       "1  http://www.boxofficemojo.com/movies/?id=spider...   Sony    373585825.0   \n",
       "2  http://www.boxofficemojo.com/movies/?id=passio...     NM    370274604.0   \n",
       "3  http://www.boxofficemojo.com/movies/?id=meetth...   Uni.    279261160.0   \n",
       "4  http://www.boxofficemojo.com/movies/?id=incred...     BV    261441092.0   \n",
       "\n",
       "   totaltheater  openingusgross$  openingtheaters opendate closedate  \\\n",
       "0        4223.0      108037878.0           4163.0     5/19     11/25   \n",
       "1        4166.0       88156227.0           4152.0     6/30     12/19   \n",
       "2        3408.0       83848082.0           3043.0     2/25      7/29   \n",
       "3        3554.0       46120980.0           3518.0    12/22      6/16   \n",
       "4        3933.0       70467623.0           3933.0     11/5      4/14   \n",
       "\n",
       "   critic ratings_avg  critic rating_var  user_avg  user_var  \\\n",
       "0                75.0               94.4       7.2   2.37960   \n",
       "1                83.0              115.2       7.3   2.86249   \n",
       "2                47.0              663.9       7.2   6.34920   \n",
       "3                41.0              298.8       6.3   2.78720   \n",
       "4                90.0              100.0       8.0   2.39500   \n",
       "\n",
       "                             critic_ratings_comments  \\\n",
       "0   Lightning strikes twice, but not as brilliant...   \n",
       "1   The pleasure is doubled in Spider-Man 2. Crac...   \n",
       "2   This is not a sermon or a homily, but a visua...   \n",
       "3   One of those relatively rare comedies that's ...   \n",
       "4   Pixar again hitches top-notch storytelling to...   \n",
       "\n",
       "                                 critic_ratings_list  \n",
       "0  90.0||88.0||80.0||80.0||80.0||75.0||75.0||70.0...  \n",
       "1  100.0||100.0||100.0||91.0||90.0||90.0||88.0||8...  \n",
       "2  100.0||80.0||80.0||75.0||63.0||63.0||50.0||50....  \n",
       "3  70.0||63.0||60.0||60.0||50.0||50.0||50.0||40.0...  \n",
       "4  100.0||100.0||100.0||100.0||100.0||90.0||90.0|...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boxOffice_Allfilled = pd.read_csv(\"boxOffice_Allfilled.csv\")\n",
    "Name_list = boxOffice_Allfilled.columns.tolist()\n",
    "Name_list = [item for item in Name_list if 'Unnamed' not in item]\n",
    "# kick out Unnamed columns for simplicity\n",
    "boxOffice_Allfilled = boxOffice_Allfilled[Name_list]\n",
    "boxOffice_Allfilled.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\TK\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " So gorgeously animated and so thoroughly entertaining for all ages that only an ogre would complain it's not quite as fresh as the original. \n",
      "['So', 'gorgeously', 'animated', 'thoroughly', 'entertaining', 'ages', 'ogre', 'would', 'complain', 'quite', 'fresh', 'original']\n",
      "4\n",
      "['4', '2', '1', '0', '0', '2', '0', '1', '0', '0']\n"
     ]
    }
   ],
   "source": [
    "# split the comment column to re-visit comment one by one\n",
    "test_case = boxOffice_Allfilled['critic_ratings_comments'][0].split(\"||\")[1]\n",
    "# remove stop words example\n",
    "tokenized = test_case.replace(\".\", \"\").split()\n",
    "tokenized = [item for item in tokenized if item not in stop_words]\n",
    "print(test_case)\n",
    "print(tokenized)\n",
    "\n",
    "# check the words frequency of this comment in above 10 topics\n",
    "def count_topic_frequency(text_list, topic_):\n",
    "    # make use of sub_dic here\n",
    "    # make use of the tokenized comments\n",
    "    frequency = 0\n",
    "    for word in text_list:\n",
    "        # check frequency in certain topic\n",
    "        for p in sub_dic[topic_]:\n",
    "            if p.match(word) !=None:\n",
    "                # print(word)\n",
    "                frequency += 1\n",
    "                break\n",
    "    return frequency\n",
    "\n",
    "# one test case for positive emotion\n",
    "print(count_topic_frequency(tokenized, topics[0]))\n",
    "\n",
    "# count the frequency for all the topic\n",
    "# and return frequency list\n",
    "def count_frequency(text_, topic_list):\n",
    "    frequency_list = [0]*len(topic_list)\n",
    "    for i in range(len(topic_list)):\n",
    "        frequency = count_topic_frequency(text_, topic_list[i])\n",
    "        frequency_list[i] = str(frequency)\n",
    "    return frequency_list\n",
    "\n",
    "# one text case for the first comment\n",
    "print(count_frequency(tokenized, topics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['7', '2', '3', '3', '0', '1', '0', '1', '0', '0'], ['4', '2', '1', '0', '0', '2', '0', '1', '0', '0'], ['5', '1', '1', '0', '0', '0', '1', '0', '0', '0'], ['1', '2', '0', '0', '1', '1', '0', '0', '0', '0'], ['5', '2', '2', '1', '0', '0', '0', '0', '1', '0'], ['2', '0', '0', '0', '0', '0', '0', '0', '0', '1'], ['4', '1', '3', '2', '2', '1', '2', '0', '0', '0'], ['6', '2', '1', '2', '1', '1', '1', '0', '1', '0'], ['1', '1', '0', '0', '2', '1', '1', '0', '0', '0'], ['2', '3', '0', '0', '0', '0', '0', '0', '0', '0']]\n"
     ]
    }
   ],
   "source": [
    "# Now go through all the comments for the first movie to test\n",
    "def count_frequency_AllComments(comment_para, topic_list):\n",
    "    # make use of boxOffice_Allfilled comments column\n",
    "    # to fill comment_para\n",
    "    split = comment_para.split(\"||\")\n",
    "    # initialize for all the splitted comments \n",
    "    result = [np.nan]*len(split)\n",
    "    for i in range(len(split)):\n",
    "        # need to tokenize comment string first\n",
    "        tokenized = split[i].replace(\".\", \"\").split()\n",
    "        tokenized = [item for item in tokenized if item not in stop_words]\n",
    "        result[i] = count_frequency(tokenized, topics)\n",
    "    return result\n",
    "\n",
    "# one test case\n",
    "print(count_frequency_AllComments(boxOffice_Allfilled['critic_ratings_comments'][0], topics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now update the table by the frequency nested list\n",
    "boxOffice_Allfilled['critic_comment_topic_frequency'] = np.nan\n",
    "\n",
    "# over 2400 rows in total\n",
    "for i in range(len(boxOffice_Allfilled)):\n",
    "    # need to check available comments para first\n",
    "    if str(boxOffice_Allfilled['critic_ratings_comments'][i]) != \"nan\":\n",
    "        result = count_frequency_AllComments(boxOffice_Allfilled['critic_ratings_comments'][i], topics)\n",
    "        # flatten = [str(item) for sublist in list for item in sublist]\n",
    "        boxOffice_Allfilled['critic_comment_topic_frequency'][i] = result\n",
    "    # process\n",
    "    if i%200 == 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>bomrank</th>\n",
       "      <th>remove</th>\n",
       "      <th>bomtitle</th>\n",
       "      <th>imdblink</th>\n",
       "      <th>bomlink</th>\n",
       "      <th>studio</th>\n",
       "      <th>totalusgross$</th>\n",
       "      <th>totaltheater</th>\n",
       "      <th>openingusgross$</th>\n",
       "      <th>openingtheaters</th>\n",
       "      <th>opendate</th>\n",
       "      <th>closedate</th>\n",
       "      <th>critic ratings_avg</th>\n",
       "      <th>critic rating_var</th>\n",
       "      <th>user_avg</th>\n",
       "      <th>user_var</th>\n",
       "      <th>critic_ratings_comments</th>\n",
       "      <th>critic_ratings_list</th>\n",
       "      <th>critic_comment_topic_frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2004.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Shrek 2</td>\n",
       "      <td>http://www.imdb.com/title/tt0298148/</td>\n",
       "      <td>http://www.boxofficemojo.com/movies/?id=shrek2...</td>\n",
       "      <td>DW</td>\n",
       "      <td>441226247.0</td>\n",
       "      <td>4223.0</td>\n",
       "      <td>108037878.0</td>\n",
       "      <td>4163.0</td>\n",
       "      <td>5/19</td>\n",
       "      <td>11/25</td>\n",
       "      <td>75.0</td>\n",
       "      <td>94.4</td>\n",
       "      <td>7.2</td>\n",
       "      <td>2.37960</td>\n",
       "      <td>Lightning strikes twice, but not as brilliant...</td>\n",
       "      <td>90.0||88.0||80.0||80.0||80.0||75.0||75.0||70.0...</td>\n",
       "      <td>[[7, 2, 3, 3, 0, 1, 0, 1, 0, 0], [4, 2, 1, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2004.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Spider-Man 2</td>\n",
       "      <td>http://www.imdb.com/title/tt0316654/</td>\n",
       "      <td>http://www.boxofficemojo.com/movies/?id=spider...</td>\n",
       "      <td>Sony</td>\n",
       "      <td>373585825.0</td>\n",
       "      <td>4166.0</td>\n",
       "      <td>88156227.0</td>\n",
       "      <td>4152.0</td>\n",
       "      <td>6/30</td>\n",
       "      <td>12/19</td>\n",
       "      <td>83.0</td>\n",
       "      <td>115.2</td>\n",
       "      <td>7.3</td>\n",
       "      <td>2.86249</td>\n",
       "      <td>The pleasure is doubled in Spider-Man 2. Crac...</td>\n",
       "      <td>100.0||100.0||100.0||91.0||90.0||90.0||88.0||8...</td>\n",
       "      <td>[[8, 6, 2, 0, 0, 2, 2, 0, 2, 0], [3, 1, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2004.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Passion of the Christ</td>\n",
       "      <td>http://www.imdb.com/title/tt0335345/</td>\n",
       "      <td>http://www.boxofficemojo.com/movies/?id=passio...</td>\n",
       "      <td>NM</td>\n",
       "      <td>370274604.0</td>\n",
       "      <td>3408.0</td>\n",
       "      <td>83848082.0</td>\n",
       "      <td>3043.0</td>\n",
       "      <td>2/25</td>\n",
       "      <td>7/29</td>\n",
       "      <td>47.0</td>\n",
       "      <td>663.9</td>\n",
       "      <td>7.2</td>\n",
       "      <td>6.34920</td>\n",
       "      <td>This is not a sermon or a homily, but a visua...</td>\n",
       "      <td>100.0||80.0||80.0||75.0||63.0||63.0||50.0||50....</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 2, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Meet the Fockers</td>\n",
       "      <td>http://www.imdb.com/title/tt0290002/</td>\n",
       "      <td>http://www.boxofficemojo.com/movies/?id=meetth...</td>\n",
       "      <td>Uni.</td>\n",
       "      <td>279261160.0</td>\n",
       "      <td>3554.0</td>\n",
       "      <td>46120980.0</td>\n",
       "      <td>3518.0</td>\n",
       "      <td>12/22</td>\n",
       "      <td>6/16</td>\n",
       "      <td>41.0</td>\n",
       "      <td>298.8</td>\n",
       "      <td>6.3</td>\n",
       "      <td>2.78720</td>\n",
       "      <td>One of those relatively rare comedies that's ...</td>\n",
       "      <td>70.0||63.0||60.0||60.0||50.0||50.0||50.0||40.0...</td>\n",
       "      <td>[[4, 1, 0, 0, 1, 0, 0, 0, 0, 0], [2, 0, 1, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2004.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Incredibles</td>\n",
       "      <td>http://www.imdb.com/title/tt0317705/</td>\n",
       "      <td>http://www.boxofficemojo.com/movies/?id=incred...</td>\n",
       "      <td>BV</td>\n",
       "      <td>261441092.0</td>\n",
       "      <td>3933.0</td>\n",
       "      <td>70467623.0</td>\n",
       "      <td>3933.0</td>\n",
       "      <td>11/5</td>\n",
       "      <td>4/14</td>\n",
       "      <td>90.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.39500</td>\n",
       "      <td>Pixar again hitches top-notch storytelling to...</td>\n",
       "      <td>100.0||100.0||100.0||100.0||100.0||90.0||90.0|...</td>\n",
       "      <td>[[2, 0, 0, 0, 0, 0, 0, 0, 0, 0], [3, 1, 0, 1, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     year  bomrank  remove                   bomtitle  \\\n",
       "0  2004.0      1.0     NaN                    Shrek 2   \n",
       "1  2004.0      2.0     NaN               Spider-Man 2   \n",
       "2  2004.0      3.0     NaN  The Passion of the Christ   \n",
       "3  2004.0      4.0     NaN           Meet the Fockers   \n",
       "4  2004.0      5.0     NaN            The Incredibles   \n",
       "\n",
       "                               imdblink  \\\n",
       "0  http://www.imdb.com/title/tt0298148/   \n",
       "1  http://www.imdb.com/title/tt0316654/   \n",
       "2  http://www.imdb.com/title/tt0335345/   \n",
       "3  http://www.imdb.com/title/tt0290002/   \n",
       "4  http://www.imdb.com/title/tt0317705/   \n",
       "\n",
       "                                             bomlink studio  totalusgross$  \\\n",
       "0  http://www.boxofficemojo.com/movies/?id=shrek2...     DW    441226247.0   \n",
       "1  http://www.boxofficemojo.com/movies/?id=spider...   Sony    373585825.0   \n",
       "2  http://www.boxofficemojo.com/movies/?id=passio...     NM    370274604.0   \n",
       "3  http://www.boxofficemojo.com/movies/?id=meetth...   Uni.    279261160.0   \n",
       "4  http://www.boxofficemojo.com/movies/?id=incred...     BV    261441092.0   \n",
       "\n",
       "   totaltheater  openingusgross$  openingtheaters opendate closedate  \\\n",
       "0        4223.0      108037878.0           4163.0     5/19     11/25   \n",
       "1        4166.0       88156227.0           4152.0     6/30     12/19   \n",
       "2        3408.0       83848082.0           3043.0     2/25      7/29   \n",
       "3        3554.0       46120980.0           3518.0    12/22      6/16   \n",
       "4        3933.0       70467623.0           3933.0     11/5      4/14   \n",
       "\n",
       "   critic ratings_avg  critic rating_var  user_avg  user_var  \\\n",
       "0                75.0               94.4       7.2   2.37960   \n",
       "1                83.0              115.2       7.3   2.86249   \n",
       "2                47.0              663.9       7.2   6.34920   \n",
       "3                41.0              298.8       6.3   2.78720   \n",
       "4                90.0              100.0       8.0   2.39500   \n",
       "\n",
       "                             critic_ratings_comments  \\\n",
       "0   Lightning strikes twice, but not as brilliant...   \n",
       "1   The pleasure is doubled in Spider-Man 2. Crac...   \n",
       "2   This is not a sermon or a homily, but a visua...   \n",
       "3   One of those relatively rare comedies that's ...   \n",
       "4   Pixar again hitches top-notch storytelling to...   \n",
       "\n",
       "                                 critic_ratings_list  \\\n",
       "0  90.0||88.0||80.0||80.0||80.0||75.0||75.0||70.0...   \n",
       "1  100.0||100.0||100.0||91.0||90.0||90.0||88.0||8...   \n",
       "2  100.0||80.0||80.0||75.0||63.0||63.0||50.0||50....   \n",
       "3  70.0||63.0||60.0||60.0||50.0||50.0||50.0||40.0...   \n",
       "4  100.0||100.0||100.0||100.0||100.0||90.0||90.0|...   \n",
       "\n",
       "                      critic_comment_topic_frequency  \n",
       "0  [[7, 2, 3, 3, 0, 1, 0, 1, 0, 0], [4, 2, 1, 0, ...  \n",
       "1  [[8, 6, 2, 0, 0, 2, 2, 0, 2, 0], [3, 1, 0, 0, ...  \n",
       "2  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 2, 0, 0, ...  \n",
       "3  [[4, 1, 0, 0, 1, 0, 0, 0, 0, 0], [2, 0, 1, 0, ...  \n",
       "4  [[2, 0, 0, 0, 0, 0, 0, 0, 0, 0], [3, 1, 0, 1, ...  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boxOffice_Allfilled.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxOffice_Allfilled.to_excel(\"comments_frequency.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
