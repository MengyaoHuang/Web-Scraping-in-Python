{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Scrapping Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# package use\n",
    "import requests\n",
    "import urllib.request\n",
    "import time\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import copy\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set the url to the website and access the site with our requests library\n",
    "url = 'http://web.mta.info/developers/turnstile.html'\n",
    "response = requests.get(url)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next we parse the html with BeautifulSoup so that we can work with a nicer, nested BeautifulSoup data structure\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "# print soup to show the nested data structure\n",
    "# soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"http://www.mta.info\"><img alt=\"Go to MTA homepage\" src=\"/template/images/mta_info.gif\"/></a>,\n",
       " <a href=\"/accessibility\">Accessibility</a>,\n",
       " <a href=\"http://assistive.usablenet.com/tt/http://www.mta.info\">Text-only</a>,\n",
       " <a href=\"/selfserve\">Customer Self-Service</a>,\n",
       " <a href=\"/mta/employment/\">Employment</a>,\n",
       " <a href=\"/faqs.htm\">FAQs/Contact Us</a>,\n",
       " <a href=\"http://www.mta.info\" style=\"padding-left:18px;\">Home</a>,\n",
       " <a href=\"http://www.mta.info\">MTA Home</a>,\n",
       " <a href=\"http://www.mta.info/nyct\">NYC Subways and Buses</a>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We use the method .findAll to locate all of our <a> tags for the first one to ten records\n",
    "soup.findAll('a')[1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation for the tag records above:\n",
    "- Explanation: This code gives us every line of code that has an <a> tag. \n",
    "- The information that we are interested in starts on line 36. Not all links are relevant to what we want, but most of it is, so we can easily slice from line 36."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a href=\"data/nyct/turnstile/turnstile_190323.txt\">Saturday, March 23, 2019</a>\n"
     ]
    }
   ],
   "source": [
    "# let’s extract the actual link that we want. Let’s test out the first link\n",
    "# Notice that all the .txt files are inside the <a> tag following the line above\n",
    "one_a_tag = soup.findAll('a')[36]\n",
    "print(one_a_tag)\n",
    "# extract the address of txt\n",
    "link = one_a_tag['href']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation for operations above:\n",
    "- This code saves ‘data/nyct/turnstile/turnstile_190316.txt’ to our variable link. The full url to download the data is actually ‘http://web.mta.info/developers/data/nyct/turnstile/turnstile_190316.txt’ which I discovered by clicking on the first data file on the website as a test.\n",
    "- We can use our urllib.request library to download this file path to our computer. We provide request.urlretrieve with two parameters: file url and the filename. For my files, I named them “turnstile_180922.txt”, “turnstile_180901”, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./turnstile_190323.txt', <http.client.HTTPMessage at 0x16e82b723c8>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create full download url string\n",
    "download_url = 'http://web.mta.info/developers/'+ link\n",
    "urllib.request.urlretrieve(download_url,'./'+link[link.find('/turnstile_')+1:]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last but not least, we should include this line of code \n",
    "# so that we can pause our code for a second \n",
    "# so that we are not spamming the website with requests.\n",
    "# This helps us avoid getting flagged as a spammer\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- useful tutorial websites: \n",
    "\n",
    "https://www.dataquest.io/blog/web-scraping-tutorial-python/\n",
    "\n",
    "https://stackoverflow.com/questions/46015006/how-to-scrape-the-first-n-paragraphs-from-a-url\n",
    "\n",
    "https://cfss.uchicago.edu/webdata005_scraping.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>photoimage</th>\n",
       "      <th>actorname</th>\n",
       "      <th>actorimdb</th>\n",
       "      <th>dateofbirth</th>\n",
       "      <th>placeofbirth</th>\n",
       "      <th>minibio</th>\n",
       "      <th>trivia</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>Domestic</th>\n",
       "      <th>bio_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>A.R. Murugadoss</td>\n",
       "      <td>http://www.imdb.com/name/nm1436693/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Aanand Rai</td>\n",
       "      <td>http://www.imdb.com/name/nm2399862/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Aaron Schneider</td>\n",
       "      <td>http://www.imdb.com/name/nm0773689/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   photoimage        actorname                            actorimdb  \\\n",
       "0         NaN  A.R. Murugadoss  http://www.imdb.com/name/nm1436693/   \n",
       "1         NaN       Aanand Rai  http://www.imdb.com/name/nm2399862/   \n",
       "2         NaN  Aaron Schneider  http://www.imdb.com/name/nm0773689/   \n",
       "\n",
       "   dateofbirth  placeofbirth  minibio  trivia  race  gender  Domestic  bio_url  \n",
       "0          NaN           NaN      NaN     NaN   NaN     NaN         0      NaN  \n",
       "1          NaN           NaN      NaN     NaN   NaN     NaN         0      NaN  \n",
       "2          NaN           NaN      NaN     NaN   NaN     NaN         1      NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read table and show the first five lines\n",
    "director_table = pd.read_csv('director table.csv', encoding='ISO-8859-1')\n",
    "director_table['bio_url'] = np.nan\n",
    "director_table.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in\n",
    "# director_table['Domestic'][0] = np.nan\n",
    "# director_table.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_ = np.mean(director_table[director_table['Domestic'] != np.nan])['Domestic']\n",
    "# mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# director_table['Domestic'] = director_table['Domestic'].fillna(mean_)\n",
    "# director_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gender-guesser package\n",
    "This package uses the underlying data from the program “gender” by Jorg Michael (described here). \n",
    "Its use is pretty straightforward.\n",
    "\n",
    "https://pypi.org/project/gender-guesser/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some hint on how to extract those information\n",
    "- dateofbirth: extract from the profile\n",
    "- placeofbirth: extract from the profie\n",
    "- minibio: extract from the \"view more bio\" link\n",
    "- trivia: extract from the \"vie more bio\" link\n",
    "- race: depends\n",
    "- gender: deduce from the mini_bio by detecting him or her & otherwise use gender-guesser package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect whether people have \"view more bio\" or not and record\n",
    "def detect_bio_link(url):\n",
    "    response = requests.get(url)\n",
    "    # form the txt\n",
    "    # call BeautifulSoup data structure to work\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    \n",
    "    mini_bio_url_num = 0\n",
    "    # Find all the links on the page\n",
    "    for link in soup.find_all('a', href=True):\n",
    "        # find the mini_bio page\n",
    "        if \"bio_sm\" in link['href']:\n",
    "            # calculate how many it finds\n",
    "            mini_bio_url_num += 1\n",
    "            mini_bio_url = link['href']\n",
    "            mini_bio_url = \"https://www.imdb.com\" + mini_bio_url\n",
    "    # check\n",
    "    if mini_bio_url_num == 1:\n",
    "        return True, mini_bio_url\n",
    "    else:\n",
    "        mini_bio_url = \" \"\n",
    "        return False, mini_bio_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decide number of directors to scrap\n",
    "length = len(director_table)\n",
    "# make a copy to modify the original table\n",
    "director_table_bioAdd = copy.deepcopy(director_table)\n",
    "\n",
    "# update and fill the new table\n",
    "for i in range(length):\n",
    "    judge, mini_bio_url_add = detect_bio_link(director_table['actorimdb'][i])\n",
    "    if judge:\n",
    "        director_table_bioAdd['bio_url'][i] = mini_bio_url_add\n",
    "    # keep track of process\n",
    "    if i%200 == 0:\n",
    "        print(i)\n",
    "# write csv to store fist\n",
    "director_table_bioAdd.to_csv('bio_url.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'director_table_bioAdd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-832766dde006>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# after check\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdirector_table_bioAdd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'director_table_bioAdd' is not defined"
     ]
    }
   ],
   "source": [
    "# after check\n",
    "director_table_bioAdd.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operation on director with bio urls first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>photoimage</th>\n",
       "      <th>actorname</th>\n",
       "      <th>actorimdb</th>\n",
       "      <th>dateofbirth</th>\n",
       "      <th>placeofbirth</th>\n",
       "      <th>minibio</th>\n",
       "      <th>trivia</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>Domestic</th>\n",
       "      <th>bio_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>A.R. Murugadoss</td>\n",
       "      <td>http://www.imdb.com/name/nm1436693/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.imdb.com/name/nm1436693/bio?ref_=n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Aanand Rai</td>\n",
       "      <td>http://www.imdb.com/name/nm2399862/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.imdb.com/name/nm2399862/bio?ref_=n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Aaron Schneider</td>\n",
       "      <td>http://www.imdb.com/name/nm0773689/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.imdb.com/name/nm0773689/bio?ref_=n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   photoimage        actorname                            actorimdb  \\\n",
       "0         NaN  A.R. Murugadoss  http://www.imdb.com/name/nm1436693/   \n",
       "1         NaN       Aanand Rai  http://www.imdb.com/name/nm2399862/   \n",
       "2         NaN  Aaron Schneider  http://www.imdb.com/name/nm0773689/   \n",
       "\n",
       "   dateofbirth  placeofbirth  minibio  trivia  race  gender  Domestic  \\\n",
       "0          NaN           NaN      NaN     NaN   NaN     NaN         0   \n",
       "1          NaN           NaN      NaN     NaN   NaN     NaN         0   \n",
       "2          NaN           NaN      NaN     NaN   NaN     NaN         1   \n",
       "\n",
       "                                             bio_url  \n",
       "0  https://www.imdb.com/name/nm1436693/bio?ref_=n...  \n",
       "1  https://www.imdb.com/name/nm2399862/bio?ref_=n...  \n",
       "2  https://www.imdb.com/name/nm0773689/bio?ref_=n...  "
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bio_url_fill = director_table_bioAdd[director_table_bioAdd['bio_url'].notnull()]\n",
    "bio_url_fill = bio_url_fill.reset_index(drop=True)\n",
    "\n",
    "bio_url_notfill = director_table_bioAdd.append(bio_url_fill).drop_duplicates(keep=False)\n",
    "bio_url_notfill = bio_url_notfill.reset_index(drop=True)\n",
    "bio_url_fill.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract dateofbirth and placeofbirth information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of bio url filled data set:  1362\n"
     ]
    }
   ],
   "source": [
    "print(\"length of bio url filled data set: \", len(bio_url_fill))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract birth date & place at least\n",
    "# and minibio and trivia information\n",
    "def extract_info(url):\n",
    "    response_mini = requests.get(url)\n",
    "    # still form the text\n",
    "    soup_mini = BeautifulSoup(response_mini.text, \"html.parser\")\n",
    "    \n",
    "    # extract birth date and place first\n",
    "    birth_monthday = \" \"\n",
    "    birth_year = \" \"\n",
    "    placeofbirth = \" \"\n",
    "    for link in soup_mini.find_all('a', href=True):\n",
    "        if \"birth_monthday\" in link['href']:\n",
    "            birth_monthday = link.string\n",
    "        if \"birth_year\" in link['href']:\n",
    "            birth_year = link.string\n",
    "        if \"birth_place\" in link['href']:\n",
    "            placeofbirth = link.string\n",
    "    # form date of birth string\n",
    "    dateofbirth = birth_monthday+\" \"+birth_year\n",
    "    \n",
    "    # extract all relevant information -- topics and content\n",
    "    # soda odd and soda even for content, li_group for title\n",
    "    table = soup_mini.find_all(True, {\"class\": {\"soda odd\", \"soda even\", \"li_group\"}})\n",
    "    # extract all the text first\n",
    "    table_text = []\n",
    "    for i in range(len(table)):\n",
    "        table_text.append(table[i].get_text(strip=True))\n",
    "    \n",
    "    # extract mini_bio and trivia now\n",
    "    mini_trivia_para = [\" \", \" \"]\n",
    "    search_title = [\"Mini Bio\", \"Trivia\"]\n",
    "    for j in range(len(search_title)):\n",
    "        for i in range(len(table_text)):\n",
    "            if search_title[j] in table_text[i]:\n",
    "                # extract the number of records to append after\n",
    "                numOfRecord = re.sub(\"\\D\", \"\", table_text[i])\n",
    "                # fill in the information\n",
    "                mini_trivia_para[j] = '/'.join(table_text[(i+1):(i+1+int(numOfRecord))])\n",
    "                break\n",
    "                \n",
    "    return dateofbirth, placeofbirth, mini_trivia_para[0], mini_trivia_para[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill the information now\n",
    "length = len(bio_url_fill)\n",
    "for count in range(length):\n",
    "    url = bio_url_fill['bio_url'][count]\n",
    "    birthday_fill, place_fill, mini_fill, trivia_fill = extract_info(url)\n",
    "    bio_url_fill['dateofbirth'][count] = birthday_fill\n",
    "    bio_url_fill['placeofbirth'][count] = place_fill\n",
    "    bio_url_fill['minibio'][count] = mini_fill\n",
    "    bio_url_fill['trivia'][count] = trivia_fill\n",
    "    if count % 100 == 0:\n",
    "        print(count)\n",
    "# write to csv\n",
    "bio_url_fill.to_csv(\"bio_url_fill.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operation on director without bio urls now\n",
    "\n",
    "- Since they have no bio urls, minibio and trivia information would be absent\n",
    "- Try to extract their birthplace and birthday information if possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of bio url not filled data set:  75\n"
     ]
    }
   ],
   "source": [
    "print(\"length of bio url not filled data set: \", len(bio_url_notfill))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>photoimage</th>\n",
       "      <th>actorname</th>\n",
       "      <th>actorimdb</th>\n",
       "      <th>dateofbirth</th>\n",
       "      <th>placeofbirth</th>\n",
       "      <th>minibio</th>\n",
       "      <th>trivia</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>Domestic</th>\n",
       "      <th>bio_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Aaron Seltzer</td>\n",
       "      <td>http://www.imdb.com/name/nm0783536/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Abhishek Varman</td>\n",
       "      <td>http://www.imdb.com/name/nm2831530/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Adam Chapman</td>\n",
       "      <td>http://www.imdb.com/name/nm7920865/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   photoimage        actorname                            actorimdb  \\\n",
       "0         NaN    Aaron Seltzer  http://www.imdb.com/name/nm0783536/   \n",
       "1         NaN  Abhishek Varman  http://www.imdb.com/name/nm2831530/   \n",
       "2         NaN     Adam Chapman  http://www.imdb.com/name/nm7920865/   \n",
       "\n",
       "   dateofbirth  placeofbirth  minibio  trivia  race  gender  Domestic bio_url  \n",
       "0          NaN           NaN      NaN     NaN   NaN     NaN         1     NaN  \n",
       "1          NaN           NaN      NaN     NaN   NaN     NaN         0     NaN  \n",
       "2          NaN           NaN      NaN     NaN   NaN     NaN         1     NaN  "
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bio_url_notfill.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract birth information for notfill data set--function\n",
    "def extract_birth_notfill(url):\n",
    "    response_mini = requests.get(url)\n",
    "    # still form the text\n",
    "    soup_mini = BeautifulSoup(response_mini.text, \"html.parser\")\n",
    "\n",
    "    birth_monthday = \" \"\n",
    "    birth_year = \" \"\n",
    "    placeofbirth = \" \"\n",
    "    for link in soup_mini.find_all('a', href=True):\n",
    "        if \"birth_monthday\" in link['href']:\n",
    "            birth_monthday = link.string\n",
    "        if \"birth_year\" in link['href']:\n",
    "            birth_year = link.string\n",
    "        if \"birth_place\" in link['href']:\n",
    "            placeofbirth = link.string\n",
    "    # form date of birth string\n",
    "    dateofbirth = birth_monthday+\" \"+birth_year\n",
    "    \n",
    "    return dateofbirth, placeofbirth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract birth information for notfill data set\n",
    "length_notfill = len(bio_url_notfill)\n",
    "for i in range(length_notfill):\n",
    "    date, place = extract_birth_notfill(bio_url_notfill['actorimdb'][i])\n",
    "    bio_url_notfill['dateofbirth'][i] = date\n",
    "    bio_url_notfill['placeofbirth'][i] = place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the total information\n",
    "bio_url_total = bio_url_fill.append(bio_url_notfill, ignore_index=True)\n",
    "# clean messy string \"Born Today\"\n",
    "bio_url_total['dateofbirth'] = bio_url_total['dateofbirth'].str.replace(\"Born Today\", \"\")\n",
    "# write to csv\n",
    "bio_url_total.to_csv(\"bio_url_total.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deduce the gender information from previous columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deduce the race information from previous columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Collection and bio/trivia text analysis\n",
    "- collect their images to code their demographic background, possibly from IMDB by collecting data on observations that has a value of 1 on column 'Domestic' (1170 out of 1437). \n",
    "- how to sort out necessary information from the bio / trivia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the data frame eventually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
